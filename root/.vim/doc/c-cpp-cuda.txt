vim:ft=help
*c-cpp-cuda*

======================================================================================
LLVM Toolchains

--------------------------------------------------------------------------------------
*clangd*

用户全局配置文件: `~/.config/clangd/config.yaml`

项目目录 compile_flags.txt

clangd设置`compile_commands.json`文件位置为`build/release/compile_commands.json`

`.clangd`文件中添加

See: https://www.reddit.com/r/neovim/comments/vj0e16/how_to_specify_location_of_compile_commandsjson/
>
	CompileFlags:
	  CompilationDatabase: build/       # Search build/ directory for compile_commands.json
<
同时clangd启动命令添加`--compile-commands-dir=build/release`

--------------------------------------------------------------------------------------
Clangd 配置问题

clangd无法解析OpenMP pragma https://github.com/clangd/clangd/issues/1640
暂时的解决方案：在`.clangd`文件中添加
>yaml
    CompileFlags:
      Remove: [-fopenmp]
<
clangd还没实现outgoing calls in call hierarchy https://github.com/llvm/llvm-project/pull/77556

clangd omp.h not found ~

locate /omp.h 找到omp.h文件位置，然后在`.clangd`文件中添加
>yaml
    CompileFlags:
      Add:
        - -isystem/usr/lib/gcc/x86_64-linux-gnu/13/include/
<

clangd / |ccls| 找不到c++系统头文件解决方法 ~

安装当前系统最新的libstdc++

>
	apt search libstdc++
	apt install libstdc++-12-dev
<

https://stackoverflow.com/questions/74785927/clangd-doesnt-recognize-standard-headers

查看当前系统安装的libstdc++版本
>
	ls /usr/include/c++
<
clang: In included file: use of undeclared identifier '__builtin_ia32_prefetch' 解决方法 ~

由于编译器未启用特定的处理器架构或指令集支持所致。这个内建函数是用于 x86
平台的特定指令。如果没有正确设置目标架构，编译器可能无法识别这些内建函数。

方法一：添加编译选项
>yaml
    CompileFlags:
      Add: [-march=x86-64]
<

方法二：添加头文件
>cpp
    #include <xmmintrin.h>
<
--------------------------------------------------------------------------------------

*clang-format* `:%!clang-format` or `:'<,'>!clang-format`.
No need of `Plug 'rhysd/vim-clang-format'`

*clang-tidy*
output to quickfix list: >
  :CExprsys clang-tidy hello.cpp
<

*Makefile*

= 延迟赋值，使用到变量的时候才确定变量的值
:= 立即赋值

======================================================================================
Ccls

Oceanbase uses ccls https://github.com/oceanbase/oceanbase/blob/ed4ed014ef2f2a904c64e04331ac4dc1ccf2b778/docs/ide-settings.md

In the C/C++ LSP domain, the famous tools are clangd and ccls. Here we recommend ccls, because:

- The speed of building index of ccls is slower than that of clangd, but after building, the speed of accessing index of ccls is faster than that of clangd.
- Unity building doesn't be supported by clangd, but OceanBase is being built by unity, failed to build index through compile_commands.json by clangd.

======================================================================================
C++ Build & Package Management Tools

*ninja*

改变控制台输出状态。
>bash
	export NINJA_STATUS="[%r processes, %f/%t @ %o/s | %e sec]"
<

*cmake*

>bash
    pip install cmake-language-server cmakelang
<

CMake 4种编译类型 ~

Debug, Release, RelWithDebInfo, MinSizeRel

https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html

CMake 显示编译命令 ~

Makefile: 添加 `set(CMAKE_VERBOSE_MAKEFILE ON)` 或者
>bash
	cmake -DCMAKE_VERBOSE_MAKEFILE=ON ..
<

或者
>bash
	make VERBOSE=1
<

Ninja:
>bash
	cmake -DCMAKE_VERBOSE_MAKEFILE=ON -G Ninja ..
	ninja -v
<

调试CMake ~

输出 CMake 执行的每一步操作，适用于需要详细调试信息的场景。
>bash
	cmake --trace --trace-expand ..
<

CMake导出compile_commands.json ~
>bash
    cmake -DCMAKE_EXPORT_COMPILE_COMMANDS=ON ..
<
--------------------------------------------------------------------------------------

*CPM.cmake* https://github.com/cpm-cmake/CPM.cmake

使用项目：rapidsai/RAFT

*conan1*

使用项目：milvus

*bazel*

使用项目：HA3

*conan2*

*vcpkg*

*xmake*

|conda|

使用项目：rapidsai/RAFT

--------------------------------------------------------------------------------------
*c++20-module*

Error:
target contains C++ module sources which are not supported by the generator

Solution:
默认的make换为Ninja

Error:
CMAKE_CXX_COMPILER_CLANG_SCAN_DEPS-NOTFOUND: not found

Solution:
手动添加CMAKE_CXX_COMPILER_CLANG_SCAN_DEPS
set(CMAKE_CXX_COMPILER_CLANG_SCAN_DEPS clang-scan-deps-17)

apt安装最新 *gnu-toolchain*
https://launchpad.net/~ubuntu-toolchain-r/+archive/ubuntu/test

安装最新 *llvm-toolchain*
https://apt.llvm.org/

在Ubuntu 18.04中，可以添加apt源
>
	deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic main
	deb-src http://apt.llvm.org/bionic/ llvm-toolchain-bionic main
	# Needs 'sudo add-apt-repository ppa:ubuntu-toolchain-r/test' for libstdc++ with C++20 support
	# 16
	deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-16 main
	deb-src http://apt.llvm.org/bionic/ llvm-toolchain-bionic-16 main
	# 17
	deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-17 main
	deb-src http://apt.llvm.org/bionic/ llvm-toolchain-bionic-17 main
<

添加gpg key
>
	wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | sudo apt-key add -
<

====================================================================================
*cuda*

https://docs.nvidia.com/cuda/cuda-c-programming-guide/
https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/

CUDA 安装: https://developer.nvidia.com/cuda-toolkit-archive

|nvidia-docker|

cuda对gcc/clang存在版本要求，例如

cuda 12.1
>
	clang version must be less than 16 and greater than 3.2 for cuda 12.1
	gcc versions later than 12 are not supported for cuda 12.1
<

GPU监控 ~

gpustat: `pip install gpustat`

【工具篇】如何优雅地监控显卡(GPU)使用情况？ - 聚丙烯酰胺的文章 - 知乎 https://zhuanlan.zhihu.com/p/577533593

------------------------------------------------------------------------------------
Failed to initialize NVML: Driver/library version mismatch NVML library version: 535.183

原因：kernel mod 的 Nvidia driver 的版本没有更新
解决方法：重启服务器

https://comzyh.com/blog/archives/967/
====================================================================================
*glibc*

查看glibc版本
>
	ldd --version
<
CentOS7.1 2.18
Ubuntu18.04 为2.27

许多软件依赖2.28

**gcc版本**
2024年初，CentOS 7.1: 4.8.5
Ubuntu 16.04: 5.4.0
======================================================================================
*cpp-mistakes*

使用std::copy拷贝std::vector，而非memcpy
